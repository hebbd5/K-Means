{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation\n",
    "In this guided project, we’ll play the role of a data scientist working for a credit card company. The idea of the project is similar to what we've done during the course, but now we're using a different dataset with more variables. The dataset contains information about the company’s clients and we're asked to help segment them into different groups in order to apply different business strategies for each type of customer.\n",
    "\n",
    "For instance, the company could provide higher credit limits for customers that use the card a lot, but spend little money, or even create incentives for those with high income who don't use the card as much as the company expects. In order to apply different strategies, the company needs different groups of customers.\n",
    "\n",
    "Luckily, the data engineering team has already cleaned most of the data so we can focus on building the best possible model to segment the data. Also, in a planning meeting with the Data Science coordinator, it was decided that we should use the K-means algorithm to segment the data.\n",
    "\n",
    "The company expects to receive a group for each client and an explanation of the characteristics of each group and the main points that make them different.\n",
    "\n",
    "In order to use the algorithm properly and achieve all the goals that the company has set for us, we'll go through the following steps:\n",
    "\n",
    "    - Analyze the dataset;\n",
    "    - Prepare the data for modeling;\n",
    "    - Find an appropriate number of clusters;\n",
    "    - Segment the data;\n",
    "    - Interpret and explain the results.\n",
    "\n",
    "Here's the data dictionary:\n",
    "\n",
    "- customer_id: unique identifier for each customer.\n",
    "- age: customer age in years.\n",
    "- gender: customer gender (M or F).\n",
    "- dependent_count: number of dependents of each customer.\n",
    "- education_level: level of education (\"High School\", \"Graduate\", etc.).\n",
    "- marital_status: marital status (\"Single\", \"Married\", etc.).\n",
    "- estimated_income: the estimated income for the customer projected by the data science team.\n",
    "- months_on_book: time as a customer in months.\n",
    "- total_relationship_count: number of times the customer contacted the company.\n",
    "- months_inactive_12_mon: number of months the customer did not use the credit card in the last 12 months.\n",
    "- credit_limit: customer's credit limit.\n",
    "- total_trans_amount: the overall amount of money spent on the card by the customer.\n",
    "- total_trans_count: the overall number of times the customer used the card.\n",
    "- avg_utilization_ratio: daily average utilization ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Import pandas, numpy, matplotlib, seaborn, and the KMeans() and StandardScaler() classes from scikit-learn.\n",
    "Read the 'customer_segmentation.csv' into a pandas DataFrame.\n",
    "Familiarize ourselves with the dataset. Answer questions such as:\n",
    "How big is the dataset? How many columns does it have? Do we see any particular column that doesn't use the analysis?\n",
    "What's the type of data contained in each column? Are there many categorical variables? How are we dealing with them?\n",
    "Are there any missing values?\n",
    "Look at the correlation between the columns and explain what we see.\n",
    "Plot the distribution of each numeric column and comment on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Let's start dealing with the categorical columns. There are three of them: gender, education level, and marital status.\n",
    "\n",
    "First, let's check on the gender and education_level columns.\n",
    "\n",
    "The gender column contains only 2 unique values, \"M\" and \"F\", which means it's possible to replace all the rows with 1 and 0.\n",
    "\n",
    "The education_level column contains 6 unique values. This column represents levels of education, and it's possible to rank the levels from the lowest to the highest, so it's possible to replace each unique level with a number, assuming we respect the order.\n",
    "\n",
    "But before we do the modifications, it's important to create a copy of the original DataFrame. We'll make all the modifications in the copy and leave the original DataFrame untouched so we can use it to analyze the results later.\n",
    "\n",
    "### Instructions\n",
    "1. Create a copy of the original DataFrame. Call it customers_modif, for instance.\n",
    "2. Replace the values in the gender column with 1 for \"M\" and 0 for \"F\". Use the map() or replace() methods, a lambda function with apply(), or even the numpy.where() function to perform this task.\n",
    "3. Replace the values in the education_level column in the order below. Choose how to execute this replacement.\n",
    "    - Uneducated - 0\n",
    "    - High School - 1\n",
    "    - College - 2\n",
    "    - Graduate - 3\n",
    "    - Post-Graduate - 4\n",
    "    - Doctorate - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering - Part 2\n",
    "\n",
    "Now, let's deal with the marital_status columns. This column contains these unique values:\n",
    "\n",
    "    - Single\n",
    "    - Married\n",
    "    - Divorced\n",
    "    - Unknown\n",
    "\n",
    "Unfortunately, we can't do the same for this marital_status column as for the last categorical column. As we can see, unlike the education_level column, there is no level of magnitude between \"Single\", \"Married\" or \"Divorced\", for example. We can't say that any of them is higher or better than the others, which means we can't rank these categories objectively.\n",
    "\n",
    "Therefore, we'll use one-hot-encoding to create dummy variables from this column.\n",
    "\n",
    "### Instructions\n",
    "1. Use the pandas.get_dummies() function to create a dataframe containing dummy variables for the unique values in the marital_status.\n",
    "\n",
    "2. Combine the new DataFrame with the original.\n",
    "\n",
    "3. Drop the original marital_status column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data\n",
    "\n",
    "Note that we have different scaled data across the DataFrame. The estimated_income, for instance, contains numbers in the range of dozens and hundreds of thousands, while the dependent_count column contains numbers from 1 to 5.\n",
    "\n",
    "At this point of the project we need to transform the data so it's all on the same scale.\n",
    "\n",
    "### Instructions\n",
    "1. Create a new DataFrame without the column customer_id.\n",
    "2. Instantiate an object from the scikit-learn's StandardScaler() class and fit the new DataFrame.\n",
    "3. Use the transform method to scale the data. Assign it to a different variable and print it.\n",
    "4. As the outcome of the scaler is an array, we can transform it back to a DataFrame using pd.DataFrame()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing K\n",
    "Now our dataset is ready for machine learning. The next step is to decide the best number of clusters to use in the segmentation according to the inertia metric.\n",
    "\n",
    "We'll have to create several models and compute the inertia from each of them. Then, we'll be able to plot the Elbow Curve and decide the number of clusters we'll use to segment the customers. Once we do all that, we can perform the real clusterization.\n",
    "\n",
    "### Instructions\n",
    "1. Create an empty list to store the inertia from every model.\n",
    "2. Use a for loop to the following process for different numbers of K. Loop in a range from 1 to 10, for example.\n",
    "3. For each K in the loop:\n",
    "- Instantiate a Kmeans object setting n_clusters=k.\n",
    "- Use fit_predict() to create clusters.\n",
    "- Append the inertia_ attribute of the model to the empty list.\n",
    "4. Use the list to plot the elbow curve. Decide how many clusters to use and explain this decision.\n",
    "5. Instantiate a new Kmeans object, but this time use the decided number of clusters as K.\n",
    "6. fit_predict the data and print the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing K\n",
    "Now our dataset is ready for machine learning. The next step is to decide the best number of clusters to use in the segmentation according to the inertia metric.\n",
    "\n",
    "We'll have to create several models and compute the inertia from each of them. Then, we'll be able to plot the Elbow Curve and decide the number of clusters we'll use to segment the customers. Once we do all that, we can perform the real clusterization.\n",
    "\n",
    "### Instructions\n",
    "1. Create an empty list to store the inertia from every model.\n",
    "2. Use a for loop to the following process for different numbers of K. Loop in a range from 1 to 10, for example.\n",
    "3. For each K in the loop:\n",
    "    - Instantiate a Kmeans object setting n_clusters=k.\n",
    "    - Use fit_predict() to create clusters.\n",
    "    - Append the inertia_ attribute of the model to the empty list.\n",
    "4. Use the list to plot the elbow curve. Decide how many clusters to use and explain this decision.\n",
    "5. Instantiate a new Kmeans object, but this time use the decided number of clusters as K.\n",
    "6. fit_predict the data and print the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results\n",
    "All that's left now is to analyze the results. We need to see how the variables used in the clusterization differ from cluster to cluster in order better explain what each cluster represents.\n",
    "\n",
    "We should note the most important characteristics of each cluster and how they can impact the business and marketing strategies for each type of customer.\n",
    "\n",
    "### Instructions\n",
    "1. Create a new column called CLUSTER in the original customers DataFrame. This column should contain the cluster assigned to each customer by the algorithm.\n",
    "2. Group each numeric variable by the CLUSTER column and plot a bar chart. Analyze the clusters' characteristics regarding each variable. Explain the conclusions.\n",
    "3. Create a scatter plot with different colors for each cluster of pairs of variables with a high correlation. Use seaborn.scatterplot() function with the hue parameter.\n",
    "4. Use the [pandas.crosstab()] (https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html) function to calculate the percentual distribution of each variable per cluster for the categorical columns. Use this data to plot a stacked bar chart.\n",
    "5. Explain the conclusions about each cluster: What are their main characteristics? How do they differ from the others? Can we make a business suggestion for each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "That's it for the guided steps. Here are some potential next steps:\n",
    "\n",
    "- Perform the clusterization using different numbers of clusters. Are there any differences?\n",
    "\n",
    "- Research other ways to find the best number of clusters and compare the results with the results from the elbow method.\n",
    "\n",
    "- Use fewer variables in the clusterization and explain what changes this brings to the model.\n",
    "\n",
    "You can find the solution to this project [here](https://github.com/dataquestio/solutions/blob/master/Mission745Solutions.ipynb). Curious to see what other students have done on this project? Head over to our Community to check them out. While you're there, share your own feedback! And, of course, we welcome you to share your own project and show off your hard work. Head over to our Community to share your finished Guided Project!\n",
    "\n",
    "Congratulations on completing the project!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
